{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the html content of a website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <div>\\n            <p class=\"inner-text first-item\" id=\"first\">\\n                First paragraph.\\n            </p>\\n            <p class=\"inner-text\">\\n                Second paragraph.\\n            </p>\\n        </div>\\n        <p class=\"outer-text first-item\" id=\"second\">\\n            <b>\\n                First outer paragraph.\\n            </b>\\n        </p>\\n        <p class=\"outer-text\">\\n            <b>\\n                Second outer paragraph.\\n            </b>\\n        </p>\\n    </body>\\n</html>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in case bs4 throws error try\n",
    "# !pip install --upgrade html5lib==1.0b8\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <div>\n",
      "   <p class=\"inner-text first-item\" id=\"first\">\n",
      "    First paragraph.\n",
      "   </p>\n",
      "   <p class=\"inner-text\">\n",
      "    Second paragraph.\n",
      "   </p>\n",
      "  </div>\n",
      "  <p class=\"outer-text first-item\" id=\"second\">\n",
      "   <b>\n",
      "    First outer paragraph.\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"outer-text\">\n",
      "   <b>\n",
      "    Second outer paragraph.\n",
      "   </b>\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>, <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>, <p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>, <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"inner-text\">\n",
       "                Second paragraph.\n",
       "            </p>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n                Second paragraph.\\n            '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>, <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_='outer-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>, <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_='inner-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all('p', class_='inner-text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the elements of the site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since every web page is different and html can get very large and messy, the easiest way to find elements that you are interested in is to start from the browser window. So next we will quickly look at how to find elements using the developer tools in your browser. Open the following webpage in your browser (preferably Chrome): http://forecast.weather.gov/MapClick.php?lat=21.3049&lon=-157.8579#.Wkwh8VQ-fVo \n",
    "\n",
    "Find the developer tools in your browser. (In Chrome, it's view --> developer --> developer tools or Control+Shift+C on Windows and Command+Shift+C on Mac) You should end up with a panel at the bottom or the right side of the browser like what you see below. Make sure the Elements panel is highlighted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=21.3049&lon=-157.8579\")\n",
    "soup = BeautifulSoup(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"myforecast-current-lrg\">70째F</p>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_=\"myforecast-current-lrg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"myforecast-current-lrg\">70째F</p>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_=\"myforecast-current-lrg\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup.find_all('p', class_=\"myforecast-current-lrg\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'70째F'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_=\"myforecast-current-lrg\")[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21째C'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_=\"myforecast-current-sm\")[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using dictionary for making queries and collecting response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Honolulu': [21.3049, -157.8579],\n",
       " 'Times Square': [40.757339, -73.985992],\n",
       " 'Yosemite': [37.8651011, -119.5383294]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latlon_dict = {\n",
    "    'Honolulu':[21.3049, -157.8579],\n",
    "    'Times Square':[40.757339, -73.985992],\n",
    "    'Yosemite':[37.8651011, -119.5383294]\n",
    "}\n",
    "latlon_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Honolulu\n",
      "http://forecast.weather.gov/MapClick.php?lat=21.3049&lon=-157.8579\n",
      "Times Square\n",
      "http://forecast.weather.gov/MapClick.php?lat=40.757339&lon=-73.985992\n",
      "Yosemite\n",
      "http://forecast.weather.gov/MapClick.php?lat=37.8651011&lon=-119.5383294\n"
     ]
    }
   ],
   "source": [
    "response_dict = {}\n",
    "for place,coordinates in latlon_dict.items():\n",
    "    url = \"http://forecast.weather.gov/MapClick.php?lat={}&lon={}\".format(coordinates[0], coordinates[1])\n",
    "    print(place)\n",
    "    print(url)\n",
    "    resp = requests.get(url)\n",
    "    time.sleep(3)\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    temp_C = soup.find_all('p', class_=\"myforecast-current-sm\")[0].text\n",
    "    response_dict[place] = temp_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Honolulu': '21째C', 'Times Square': '3째C', 'Yosemite': '-8째C'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current temperature in Honolulu is 21째C.\n",
      "The current temperature in Times Square is 3째C.\n",
      "The current temperature in Yosemite is -8째C.\n"
     ]
    }
   ],
   "source": [
    "for place,temperature in response_dict.items():\n",
    "    print(\"The current temperature in {} is {}.\".format(place, temperature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### saving dictinaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('mydict.npy', response_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "read_dictionary = np.load('mydict.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Honolulu': '21째C', 'Times Square': '3째C', 'Yosemite': '-8째C'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - exercise\n",
    "\n",
    "We need the zip codes of the 5 landmarks in our data. Fortunatelly Google shows the zip codes at a fixed place if using the right searchphase. <br>\n",
    "Open this link and using the Inspect tool in the browser try to find the class of the HTML element of a zip code shown at the top of the page! <br> \n",
    "https://www.google.com/search?q=San+Jose+zip+code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - check yourself\n",
    "\n",
    "The zip code is under a div of class \"title\" inside a div of class \"IAznY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - exercise\n",
    "Now use the requests library to get the html content of this page and create a BeautifulSoup object called soup from this content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Your code here\n",
    "googleresponse = requests.get(\"https://www.google.com/search?q=San+Jose+zip+code\")\n",
    "soup = BeautifulSoup(googleresponse.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your soup object is correct\n"
     ]
    }
   ],
   "source": [
    "if type(soup) == BeautifulSoup and '94089' in soup.text:\n",
    "    print('Your soup object is correct')\n",
    "else:\n",
    "    print('Your soup object is NOT correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - exercise\n",
    "Try to find all the div elements of class IAznY in your soup object. How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Your code here\n",
    "soup.find_all('div', class_='IAznY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - check yourself\n",
    "If you haven't found any div of this class you were right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - exercise\n",
    "So it looks like that the scraped HTML code doesn't have the elements you saw in the browser. The reason is that when opening the url in the browser, it uses JavaScript to format the page, but when we scraped it, only the plaine HTML was sent. <br><br>\n",
    "To see the same content in the browser disable JavaScript usage by following this directions:  https://productforums.google.com/forum/#!msg/chrome/BYOQskiuGU0/dO592rlLbJ0J). <br><br>\n",
    "Then open the page again and find using the Inspect tool find the HTML elemnt containg the zip code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - check yourself\n",
    "\n",
    "The zip codes are under a div of class \"Db7kif\" and each zip code is under a span of class \"ED44Kd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - exercise\n",
    "Try to find all the span elements of class ED44Kd in your soup object. How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Your code here\n",
    "len(soup.find_all('span', class_='ED44Kd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - check yourself\n",
    "You should find 67 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - exercise\n",
    "Make a list called zipcode_list that contains the text from all the ED44Kd span elements!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zipcode_list = []\n",
    "for zipcode in soup.find_all('span', class_='ED44Kd'):\n",
    "    zipcode_list.append(zipcode.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your list is correct\n"
     ]
    }
   ],
   "source": [
    "if sorted(zipcode_list)[0] == ',94089' and len(zipcode_list) == 67:\n",
    "    print('Your list is correct')\n",
    "else:\n",
    "    print('Your list is NOT correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - exercise\n",
    "Read in the weather csv into a pandas dataframe called station. <br>\n",
    "Create a dictionary called zipcode_dict which keys are the unique values from the landmark column and the value of each key is an empty list. You print the unique values and create the dictionary by hand or as an advanced task, try to create the dictionary without typing any landmark name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "weather = pd.read_csv('/home/esztersomos/Documents/CEU/winter_2019/merging/weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zipcode_dict = {}\n",
    "for landmark in weather['landmark'].unique():\n",
    "    zipcode_dict[landmark] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dictionary is correct\n"
     ]
    }
   ],
   "source": [
    "if sorted(list(zipcode_dict.items())) == [('Mountain View', []),\n",
    "                                         ('Palo Alto', []),\n",
    "                                         ('Redwood City', []),\n",
    "                                         ('San Francisco', []),\n",
    "                                         ('San Jose', [])]:\n",
    "    print('Your dictionary is correct')\n",
    "else:\n",
    "    print('Your dictionary is NOT correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - exercise\n",
    "Loop the keys from the zipcode_dict and for each key print the url you would use to search the zip codes of a given city in google by using string formatting. <br>\n",
    "For example if the city is Palo Alto the url should be: <br>\n",
    "https://www.google.com/search?q=Palo Alto zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/search?q=San Francisco zip code\n",
      "https://www.google.com/search?q=Palo Alto zip code\n",
      "https://www.google.com/search?q=Mountain View zip code\n",
      "https://www.google.com/search?q=San Jose zip code\n",
      "https://www.google.com/search?q=Redwood City zip code\n"
     ]
    }
   ],
   "source": [
    "for key in zipcode_dict.keys():\n",
    "    print(\"https://www.google.com/search?q={} zip code\".format(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 - exercise\n",
    "Similarly as before, loop the keys from the zipcode_dict and for each key inside the loop:\n",
    "- Get a response object to the url you would use to search the zip codes of a given city in google. <br>\n",
    "- Make a soup from that resopnse object. <br>\n",
    "- Make a list of all zip codes in the soup object. You can find the zip codes by looking for the text of the span elements of class 'ED44Kd'.<br>\n",
    "- Assign this list as value to the key in the zipcode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mountain View': [],\n",
       " 'Palo Alto': [],\n",
       " 'Redwood City': [],\n",
       " 'San Francisco': [],\n",
       " 'San Jose': []}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipcode_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for z in zipcode_dict.keys():\n",
    "    url = \"https://www.google.com/search?q={}+zip+code\".format(z).replace(' ', '+')\n",
    "    resp = requests.get(url)\n",
    "    time.sleep(2)\n",
    "    soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "    zip_list1 = []\n",
    "    zip_list = soup.find_all('span', class_=\"ED44Kd\")\n",
    "    for zz in zip_list:\n",
    "        zip_list1.append(zz.text.strip(','))\n",
    "        \n",
    "    zipcode_dict[z] = zip_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mountain View': ['94039',\n",
       "  '94040',\n",
       "  '94041',\n",
       "  '94042',\n",
       "  '94043',\n",
       "  '94085',\n",
       "  '94303'],\n",
       " 'Palo Alto': ['94020',\n",
       "  '94022',\n",
       "  '94024',\n",
       "  '94028',\n",
       "  '94301',\n",
       "  '94302',\n",
       "  '94303',\n",
       "  '94304',\n",
       "  '94306',\n",
       "  '95033'],\n",
       " 'Redwood City': ['94002',\n",
       "  '94061',\n",
       "  '94062',\n",
       "  '94063',\n",
       "  '94064',\n",
       "  '94065',\n",
       "  '94070'],\n",
       " 'San Francisco': ['94016',\n",
       "  '94102',\n",
       "  '94103',\n",
       "  '94104',\n",
       "  '94105',\n",
       "  '94107',\n",
       "  '94108',\n",
       "  '94109',\n",
       "  '94110',\n",
       "  '94111',\n",
       "  '94112',\n",
       "  '94114',\n",
       "  '94115',\n",
       "  '94116',\n",
       "  '94117',\n",
       "  '94118',\n",
       "  '94119',\n",
       "  '94120',\n",
       "  '94121',\n",
       "  '94122',\n",
       "  '94123',\n",
       "  '94124',\n",
       "  '94125',\n",
       "  '94126',\n",
       "  '94127',\n",
       "  '94129',\n",
       "  '94130',\n",
       "  '94131',\n",
       "  '94132',\n",
       "  '94133',\n",
       "  '94134',\n",
       "  '94137',\n",
       "  '94139',\n",
       "  '94140',\n",
       "  '94141',\n",
       "  '94142',\n",
       "  '94143',\n",
       "  '94144',\n",
       "  '94145',\n",
       "  '94146',\n",
       "  '94147',\n",
       "  '94151',\n",
       "  '94153',\n",
       "  '94154',\n",
       "  '94156',\n",
       "  '94158',\n",
       "  '94159',\n",
       "  '94160',\n",
       "  '94161',\n",
       "  '94162',\n",
       "  '94163',\n",
       "  '94164',\n",
       "  '94171',\n",
       "  '94172',\n",
       "  '94177',\n",
       "  '94188'],\n",
       " 'San Jose': ['94088',\n",
       "  '94089',\n",
       "  '94538',\n",
       "  '94560',\n",
       "  '95002',\n",
       "  '95008',\n",
       "  '95013',\n",
       "  '95035',\n",
       "  '95037',\n",
       "  '95050',\n",
       "  '95054',\n",
       "  '95101',\n",
       "  '95103',\n",
       "  '95106',\n",
       "  '95108',\n",
       "  '95109',\n",
       "  '95110',\n",
       "  '95111',\n",
       "  '95112',\n",
       "  '95113',\n",
       "  '95115',\n",
       "  '95116',\n",
       "  '95117',\n",
       "  '95118',\n",
       "  '95119',\n",
       "  '95120',\n",
       "  '95121',\n",
       "  '95122',\n",
       "  '95123',\n",
       "  '95124',\n",
       "  '95125',\n",
       "  '95126',\n",
       "  '95127',\n",
       "  '95128',\n",
       "  '95129',\n",
       "  '95130',\n",
       "  '95131',\n",
       "  '95132',\n",
       "  '95133',\n",
       "  '95134',\n",
       "  '95135',\n",
       "  '95136',\n",
       "  '95138',\n",
       "  '95139',\n",
       "  '95141',\n",
       "  '95148',\n",
       "  '95150',\n",
       "  '95151',\n",
       "  '95152',\n",
       "  '95153',\n",
       "  '95154',\n",
       "  '95155',\n",
       "  '95156',\n",
       "  '95157',\n",
       "  '95158',\n",
       "  '95160',\n",
       "  '95161',\n",
       "  '95164',\n",
       "  '95170',\n",
       "  '95172',\n",
       "  '95173',\n",
       "  '95190',\n",
       "  '95191',\n",
       "  '95192',\n",
       "  '95193',\n",
       "  '95194',\n",
       "  '95196']}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipcode_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 - check yourslef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dictionary is correct\n"
     ]
    }
   ],
   "source": [
    "if sorted([len(x) for x in zipcode_dict.values()]) == [7, 7, 10, 56, 67]:\n",
    "    print('Your dictionary is correct')\n",
    "else:\n",
    "    print('Your dictionary is NOT correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
