{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[1,1,1,2,2,3,4,5],\n",
    "                  'b':[10,10,11,20,0,0,40,50],\n",
    "                  'c':['apple','apple','plum','pear','plum','apple','apple','apple']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a']<3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['a']<3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_apple = df[df['c']=='apple']\n",
    "only_apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['b']==10) & (df['c']=='apple')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['a']<df['b']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_a = {'apple','plum','plum','pear'}\n",
    "set_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "US_spies = {'John','Anton','Brad','Dimitrij'}\n",
    "russian_spies = {'Pavlov', 'Mikhail', 'Dimitrij','John', 'Alexander'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loyal_US_spies = US_spies.difference(russian_spies)\n",
    "loyal_US_spies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_agents = US_spies.intersection(russian_spies)\n",
    "double_agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spies = US_spies.union(russian_spies)\n",
    "all_spies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us_df = pd.DataFrame({'spies':['Anton', 'Anton', 'Brad', 'Brad', 'Brad','Dimitrij', 'Dimitrij', 'John', 'John'],\n",
    "                     'contacted':pd.date_range(start='1/1/1960', end='1/9/1960')})\n",
    "russia_df = pd.DataFrame({'spies':['Pavlov', 'Mikhail', 'Dimitrij','John', 'Alexander', 'Pavlov', 'Mikhail', 'Dimitrij','John', 'Alexander', 'Pavlov', 'Mikhail', 'Dimitrij','John', 'Alexander'],\n",
    "                     'contacted':pd.date_range(start='1/1/1960', end='1/15/1960')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "russia_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_df['spies'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(us_df['spies'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_agents = set(us_df['spies'].tolist()).intersection(set(russia_df['spies'].tolist()))\n",
    "double_agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preparing for joining the dataframes\n",
    "\n",
    "For joining weather data to trip data, we'll have to know the landmark of each trip. For that we'll use the zip code information from the station dataframe. We also have to use the date, which first needs to be transformed. <br>\n",
    "Let's start with that!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - exercise\n",
    "Load the datasets into pandas dataframes called trip and weather.<br><br>\n",
    "Let's start with the date columns! <br>\n",
    "In the trip dataframe create two new columns called 'start_datetime' and 'end_datetime'. These should contain the values from column 'Start Date' and 'End date' converted into datetime. <br><br>\n",
    "In the weather dataframe create a new column called 'datetime' similarly from the 'Date' column.<br><br>\n",
    "Display the datatypes of these columns to check the difference between the old and the new format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (trip['Start Date'] != trip['start_date'].dt.strftime('%-m/%-d/%Y %-H:%M')).sum() == 0:\n",
    "    print('start_date column is successfully converted')\n",
    "else:\n",
    "    print('start_date column is NOT successfully converted')\n",
    "if (trip['End Date'] != trip['end_date'].dt.strftime('%-m/%-d/%Y %-H:%M')).sum() == 0:\n",
    "    print('end_date column is successfully converted')\n",
    "else:\n",
    "    print('end_date column is NOT successfully converted')\n",
    "if (weather['Date'] != weather['datetime'].dt.strftime('%-m/%-d/%Y')).sum() == 0:\n",
    "    print('datetime column is successfully converted')   \n",
    "else:\n",
    "    print('datetime column is NOT successfully converted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2 - exercise\n",
    "\n",
    "Now, that we can use the date values in the weather and the trip dataframe, let's check if they cover the same interval! <br>\n",
    "Create four variable called weather_datetime_min, weather_datetime_max, trip_start_date_min, trip_start_date_max, trip_end_date_min and trip_end_date_max containing the minimum and maximum values from the named columns.<br>\n",
    "Display them to see if they the two dataframes have the same minimum and maximum date!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'weather_datetime_min':pd.Timestamp('2013-08-29 00:00:00'),\n",
    "              'weather_datetime_max':pd.Timestamp('2014-02-28 00:00:00'),\n",
    "              'trip_start_date_min':pd.Timestamp('2013-08-29 09:08:00'),\n",
    "              'trip_start_date_max':pd.Timestamp('2023-08-29 14:13:00'),\n",
    "              'trip_end_date_min':pd.Timestamp('2013-08-29 09:11:00'),\n",
    "              'trip_end_date_max':pd.Timestamp('2014-03-02 16:52:00')}\n",
    "for k,v in result_dict.items():\n",
    "    if eval(k) == v:\n",
    "        print('{} is correct'.format(k))\n",
    "    else:\n",
    "        print('{} is NOT correct'.format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - exercise\n",
    "\n",
    "So it looks like that there are some rows with invalid start_date in the trip dataframe. <br>\n",
    "Let's see, in how many rows is the start_date later than the latest end_date. You can use the trip_end_date_max variable you've created in the previous task. <br>\n",
    "Save the number of rows into a variable called nb_not_valid_start_date_rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nb_not_valid_start_date_rows == 20:\n",
    "    print('nb_not_valid_start_date_rows is correct')\n",
    "else:\n",
    "    print('nb_not_valid_start_date_rows is NOT correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - exercise\n",
    "\n",
    "As the number of row with invalid start_date is not high, let's just drop them. <br>\n",
    "Create a new dataframe called trip_valid_start where these rows are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(trip_valid_start) == 143985 and trip_valid_start['start_date'].max()==pd.Timestamp('2014-02-28 23:20:00'):\n",
    "    print('New dataframe is correct')\n",
    "else:\n",
    "    print('Something is not correct with the new dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - exercise\n",
    "In the weather dataframe the datetime refers to a day, while in the trip_valid_start dataframe the dates refer to exact times. <br>\n",
    "For being able to join, we'll need to create new columns in both dataframes with only the date part of the timestamps. In the trip_valid_start dataframe we'll use the start_date to join on. <br>\n",
    "In both dataframes create column called date_to_join in which the datetime/start_date column is transformed to datetime.date format! <br>\n",
    "Using set().intersection and set().difference see how many common and different values are in the date_to_join columns in the two dataframes. Create variables called nb_common and nb_different and save the result into them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nb_common == 184 and nb_different==0:\n",
    "    print('The date_to_join columns are correct')\n",
    "else:\n",
    "    print('Something is not correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 -exercise\n",
    "\n",
    "Let's save the changed dataframes to csv files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
