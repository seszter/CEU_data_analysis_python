{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "datetime\n",
    "sortolas hogy latszodjon milyen idointervallum az adat +head,tail\n",
    "utana hogy milyen weather a realis\n",
    "filterezes: ahol min > max\n",
    "ahol trip station name rossz\n",
    "kitolteni a hianyzo zip code-ot station name alapjan\n",
    "atteni stringrol int-re, hogy joinolni lehessen\n",
    "outlierezes (boxplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### majd ez alapjan kell joinilni\n",
    "landmark_dict = {94107:'San Francisco',\n",
    "                 94063:'Redwood City',\n",
    "                 94301:'Palo Alto', \n",
    "                 94041:'Mountain View', \n",
    "                 95113:'San Jose'}\n",
    "weather_df['landmark'] = weather_df['zip'].map(lambda x: landmark_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Preparing for joining the dataframes\n",
    "\n",
    "- weather and trip can be joined via date and zip code\n",
    "- weather and trip can be joined to station via finding the landmark name of the zip codes\n",
    "\n",
    "We'll go through these columns and transform them so the dataframes can be joined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - exercise\n",
    "Load the datasets into pandas dataframes called trip, weather and station.<br><br>\n",
    "Let's start with the date columns! <br>\n",
    "In the trip dataframe create two new columns called 'start_datetime' and 'end_datetime'. These should contain the values from column 'Start Date' and 'End date' converted into datetime. <br><br>\n",
    "In the weather dataframe create a new column called 'datetime' similarly from the 'Date' column.<br><br>\n",
    "Display the datatypes of these columns to check the difference between the old and the new format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esztersomos/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "### Your code here\n",
    "import pandas as pd\n",
    "\n",
    "weather = pd.read_csv('weather_filled.csv')\n",
    "trip = pd.read_csv('trip_filled.csv')\n",
    "station = pd.read_csv('station.csv')\n",
    "\n",
    "trip['start_date'] = pd.to_datetime(trip['Start Date'], format='%m/%d/%Y %H:%M')\n",
    "trip['end_date'] = pd.to_datetime(trip['End Date'], format='%m/%d/%Y %H:%M')\n",
    "weather['datetime'] = pd.to_datetime(weather['Date'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_date column is successfully converted\n",
      "end_date column is successfully converted\n",
      "datetime column is successfully converted\n"
     ]
    }
   ],
   "source": [
    "if (trip['Start Date'] != trip['start_date'].dt.strftime('%-m/%-d/%Y %-H:%M')).sum() == 0:\n",
    "    print('start_date column is successfully converted')\n",
    "else:\n",
    "    print('start_date column is NOT successfully converted')\n",
    "if (trip['End Date'] != trip['end_date'].dt.strftime('%-m/%-d/%Y %-H:%M')).sum() == 0:\n",
    "    print('end_date column is successfully converted')\n",
    "else:\n",
    "    print('end_date column is NOT successfully converted')\n",
    "if (weather['Date'] != weather['datetime'].dt.strftime('%-m/%-d/%Y')).sum() == 0:\n",
    "    print('datetime column is successfully converted')   \n",
    "else:\n",
    "    print('datetime column is NOT successfully converted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2 - exercise\n",
    "\n",
    "Now, that we can use the date values in the weather and the trip dataframe, let's check if they cover the same interval! <br>\n",
    "Create four variable called weather_datetime_min, weather_datetime_max, trip_start_date_min, trip_start_date_max, trip_end_date_min and trip_end_date_max containing the minimum and maximum values from the named columns.<br>\n",
    "Display them to see if they the two dataframes have the same minimum and maximum date!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_datetime_min = weather['datetime'].min()\n",
    "weather_datetime_max = weather['datetime'].max()\n",
    "trip_start_date_min = trip['start_date'].min()\n",
    "trip_start_date_max = trip['start_date'].max()\n",
    "trip_end_date_min = trip['end_date'].min()\n",
    "trip_end_date_max = trip['end_date'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weather_datetime_min is correct\n",
      "weather_datetime_max is correct\n",
      "trip_start_date_min is correct\n",
      "trip_start_date_max is correct\n",
      "trip_end_date_min is correct\n",
      "trip_end_date_max is correct\n"
     ]
    }
   ],
   "source": [
    "result_dict = {'weather_datetime_min':pd.Timestamp('2013-08-29 00:00:00'),\n",
    "              'weather_datetime_max':pd.Timestamp('2014-02-28 00:00:00'),\n",
    "              'trip_start_date_min':pd.Timestamp('2013-08-29 09:08:00'),\n",
    "              'trip_start_date_max':pd.Timestamp('2023-08-29 14:13:00'),\n",
    "              'trip_end_date_min':pd.Timestamp('2013-08-29 09:11:00'),\n",
    "              'trip_end_date_max':pd.Timestamp('2014-03-02 16:52:00')}\n",
    "for k,v in result_dict.items():\n",
    "    if eval(k) == v:\n",
    "        print('{} is correct'.format(k))\n",
    "    else:\n",
    "        print('{} is NOT correct'.format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - exercise\n",
    "\n",
    "So it looks like that there are some rows with invalid start_date in the trip dataframe. <br>\n",
    "Let's see, in how many rows is the start_date later than the latest end_date. You can use the trip_end_date_max variable you've created in the previous task. <br>\n",
    "Save the number of rows into a variable called nb_not_valid_start_date_rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_not_valid_start_date_rows = len(trip[trip.start_date>trip_end_date_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_not_valid_start_date_rows is correct\n"
     ]
    }
   ],
   "source": [
    "if nb_not_valid_start_date_rows == 20:\n",
    "    print('nb_not_valid_start_date_rows is correct')\n",
    "else:\n",
    "    print('nb_not_valid_start_date_rows is NOT correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - exercise\n",
    "\n",
    "As the number of row with invalid start_date is not high, let's just drop them. <br>\n",
    "Create a new dataframe called trip_valid_start where these rows are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trip_valid_start = trip[trip.start_date<=trip_end_date_max].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataframe is correct\n"
     ]
    }
   ],
   "source": [
    "if len(trip_valid_start) == 143985 and trip_valid_start['start_date'].max()==pd.Timestamp('2014-02-28 23:20:00'):\n",
    "    print('New dataframe is correct')\n",
    "else:\n",
    "    print('Something is not correct with the new dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - exercise\n",
    "In the weather dataframe the datetime refers to a day, while in the trip_valid_start dataframe the dates refer to exact times. <br>\n",
    "For being able to join, we'll need to create new columns in both dataframes with only the date part of the timestamps. In the trip_valid_start dataframe we'll use the start_date to join on. <br>\n",
    "In both dataframes create column called date_to_join in which the datetime/start_date column is transformed to datetime.date format! <br>\n",
    "Using set().intersection and set().difference see how many common and different values are in the date_to_join columns in the two dataframes. Create variables called nb_common and nb_different and save the result into them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['date_to_join'] = weather['datetime'].dt.date\n",
    "trip_valid_start['date_to_join'] = trip_valid_start['start_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_common = len(set(trip_valid_start.date_to_join.unique()).intersection(set(weather.date_to_join.unique())))\n",
    "nb_different = len(set(trip_valid_start.date_to_join.tolist()).difference(set(weather.date_to_join.tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - check yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The date_to_join columns are correct\n"
     ]
    }
   ],
   "source": [
    "if nb_common == 184 and nb_different==0:\n",
    "    print('The date_to_join columns are correct')\n",
    "else:\n",
    "    print('Something is not correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 -exercise\n",
    "\n",
    "The next column we'll use to join dataframes is the zip code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### todo ezt majd az api/scrapingnel, eloszor a station landmarkhoz kell zipcode lista, igy mehet a weather zip -> landmarkba, es a trip Zip Code is landmarkba. Viszont trip Zip Code vegyesen float es string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 16, 21, 22, 23,\n",
       "       24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41,\n",
       "       42, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62,\n",
       "       63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 80, 82,\n",
       "       83])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station.station_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66, 10, 27, 59,  4,  8, 49,  6, 28, 64, 41, 47, 67, 74, 39, 22, 58,\n",
       "       56,  9, 55,  3, 26, 61, 72, 45, 76, 62, 46, 35, 68,  5, 71, 69, 73,\n",
       "       48, 75, 70, 11, 50, 77, 65, 60, 30, 42, 34, 54, 57, 23, 37, 51, 13,\n",
       "       63,  2,  7, 36, 29, 33, 14, 12, 21, 38, 24, 16, 25, 80, 32, 31, 82,\n",
       "       83])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip['Start Terminal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([66, 10, 27, 67, 59,  5,  8, 11, 54,  4, 28, 64, 56, 47, 50, 76, 22,\n",
       "       58, 77, 74,  9, 51, 25, 72, 45, 61, 62, 46, 41, 37, 57,  3, 69, 65,\n",
       "       12, 70, 42, 71, 55, 48, 35, 23, 39, 49, 63,  6, 26, 75, 73,  2, 34,\n",
       "       68,  7, 60, 13, 36, 21, 33, 14, 29, 38, 30, 16, 24, 80, 31, 32, 82,\n",
       "       83])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip['End Terminal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
